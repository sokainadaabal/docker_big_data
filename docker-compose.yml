version: '3' 

services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    container_name: namenode
    volumes:
      - /tmp/hdfs/namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env
    ports:
      - "50070:50070"
    networks:
      net_pet:
        ipv4_address: 172.27.1.1
  
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    container_name: datanode
    volumes:
      - /tmp/hdfs/datanode:/hadoop/dfs/data
      - ./test:/test
    env_file:
      - ./hadoop.env
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    depends_on:
      - namenode
    ports:
      - "50075:50075"
    networks:
      net_pet:
        ipv4_address: 172.27.1.2
  
  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop2.7.4-java8
    container_name: resourcemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075"
    env_file:
      - ./hadoop.env

  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop2.7.4-java8
    container_name: nodemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:50070  datanode:50075 resourcemanager:8088"
    env_file:
      - ./hadoop.env
  spark-master:
    image: bde2020/spark-master:2.4.0-hadoop2.7
    container_name: spark-master
    ports:
      - 8080:8080
      - 7077:7077
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    env_file:
      - ./hadoop.env
    networks:
      net_pet:
        ipv4_address: 172.27.1.3
     
  spark-worker:
    image: bde2020/spark-worker:2.4.0-hadoop2.7
    container_name: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - HIVE_CORE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://hive-metastore/metastore
    depends_on:
      - spark-master
    ports:
      - 8081:8081
    env_file:
      - ./hadoop.env
    networks:
      net_pet:
        ipv4_address: 172.27.1.4

  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server
    env_file:
      - ./hadoop.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    ports:
      - "10000:10000"
    depends_on:
      - hive-metastore
    networks:
      net_pet:
        ipv4_address: 172.27.1.5
  
  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-metastore
    env_file:
      - ./hadoop.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432"
    ports:
      - "9083:9083"
    depends_on:
      - hive-metastore-postgresql
    networks:
      net_pet:
        ipv4_address: 172.27.1.6
  
  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
    container_name: hive-metastore-postgresql
    networks:
      net_pet:
        ipv4_address: 172.27.1.7

  zookeeper:
    image: wurstmeister/zookeeper:3.4.6
    ports:
      - "2181:2181"
    networks:
      net_pet:
        ipv4_address: 172.27.1.8
  kafka:
    image: wurstmeister/kafka:2.12-2.3.0
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 172.27.1.14
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    networks:
      net_pet:
        ipv4_address: 172.27.1.9
  zeppelin:
    image: yabhinav/zeppelin:latest
    #image: yabhinav/zeppelin:0.7.3-minimal
    volumes:
      - zeppelin-data:/zeppelin
      # - ~/Downloads/zeppelin-data:/zeppelin
    ports:
      - "19090:8080"
      - "4040:4040"
    tmpfs: /tmp
    environment:
        ZEPPELIN_MEM: "-Xmx4g"
        ZEPPELIN_INTP_MEM: "-Xmx4g"
    networks:
      net_pet:
        ipv4_address: 172.27.1.10
  hbase:
    image: pierrezemb/hbase-docker:standalone-1.3.1
    container_name: hbase
    volumes:
      - hbase_data:/hbase-data
      - hbase_zookeeper_data:/zookeeper-data
    ports:
      - "16010:16010"
    expose:
      - "8080"
      - "9090"
      - "16000"
      - "16010"
      - "16020"
      - "16030"
      
    environment:
      SERVICE_PRECONDITION: "namenode:50070 datanode:50075"
    env_file:
      - ./hbase-standalone.env
    networks:
      net_pet:
        ipv4_address: 172.27.1.11
  pig:
    image: anoopnair/pig_hadoop_debian:0.15.0
    container_name: pig
  nimbus:
    image: wurstmeister/storm-nimbus
    ports:
      - "49773:3773"
      - "49772:3772"
      - "49627:6627"
      - "22"
    links: 
      - zookeeper:zk
    networks:
      net_pet:
        ipv4_address: 172.27.1.12
  supervisor:
    image: wurstmeister/storm-supervisor
    ports:
      - "8000"
      - "22"
    links: 
      - nimbus:nimbus
      - zookeeper:zk
    networks:
      net_pet:
        ipv4_address: 172.27.1.13
  ui:
    image: wurstmeister/storm-ui
    ports:
      - "49080:8080"
      - "22"
    links: 
      - nimbus:nimbus
      - zookeeper:zk
  mysql:
    image: mysql
    container_name: mysql
    ports:
      - "3308:3308"
    environment:
      MYSQL_ROOT_PASSWORD: root
  postgres:
    image: postgres
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: root
      POSTGRES_PASSWORD: root
  waitkafka:
    image: aanand/wait
    container_name: waitkafka
    links:
      - kafka
  sqoop-server:
    image: stratio/sqoop-server:latest
    container_name: sqoopserver
    ports:
      - "8053:8080"
    links:
      - zookeeper
      - mysql
      - kafka
      - waitkafka
      - postgres
    networks:
      net_pet:
        ipv4_address: 172.27.1.14
  sqoop-shell:
    image: stratio/sqoop-shell:latest
    container_name: sqoopshell
    links:
      - sqoop-server
  
networks:
  net_pet:
    ipam:
      driver: default
      config:
        - subnet: 172.27.0.0/16
volumes:
  hbase_data:
  hbase_zookeeper_data:
  zeppelin-data:
